{
 "metadata": {
  "name": "",
  "signature": "sha256:e91ba3c3e16e0114c487d864e79ce9822c79a3abca4e278c882b8dd35efbc38d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Switchboard 'some' dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- initial imports for this notebook"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Initial dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- (EDIT THIS) go to project home folder"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd '~/tools/some_python/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/acasa/tools/some_python\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10.17.2014 - nextPOS.png   swb-search.py~             swbtranscripts.pkl         utils.py\r\n",
        "10.17.2014 - nextWord.png  swb-to-ezra.py             swbtranscripts0.pkl        utils.pyc\r\n",
        "SWB Somes.ipynb            swb-to-ezra.py~            swbxml-to-et.py            utils.py~\r\n",
        "swb-analyze.py             swbsomes.pkl               swbxml-to-et.py~\r\n",
        "swb-analyze.py~            swbsomes0.pkl              terminalHREF.txt\r\n",
        "swb-search.py              swbsomesEZRA.pkl           trans.txt\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<tt>swb-search.py</tt> extracts all <i>some</i>s tagged as Determiners. It saves them in a list of dictionaries (including a variety of information from NXT xml files), saved to disk in <tt>swbsomes.pkl</tt>. It also outputs <tt>swbtranscripts.pkl</tt>: a dictionary (indexed by filename) of dictionaries (indexed by NXT sentence ID) of lists of words & punctuation. This will be used to generate the context for annotation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('swbsomes.pkl','r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "somes = pickle.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "f = open('swbtranscripts.pkl','r')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trans = pickle.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Let's take an example <i>some</i> from Switchboard: the first one we came across."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "somes[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "{'accent': 'NoAnnotation',\n",
        " 'end': 'n/a',\n",
        " 'ezraID': 0,\n",
        " 'focus': 'NoAnnotation',\n",
        " 'nextID': 's34_18',\n",
        " 'nextPOS': 'NN',\n",
        " 'nextWord': 'time',\n",
        " 'phones': None,\n",
        " 'start': '108.241250',\n",
        " 'swbfile': 'sw2005.A',\n",
        " 'terminalID': 's34_17'}"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "somes[0]['terminalID']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "'s34_17'"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The <tt>swbfile</tt> field tells you this <i>some</i> comes from a file called </tt>sw2005.A</tt>, aka conversation # 2005, speaker A. The <tt>terminalID</tt> field tells you this hit comes from sentence number 34 in conversation # 2005 and is word number 17 in this sentence (punctuation is also counted as a word)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trans['sw2005']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "{1: ['---A:  ', ' Okay', '.'],\n",
        " 2: ['---A:  ',\n",
        "  ' Uh',\n",
        "  ' first',\n",
        "  ' um',\n",
        "  ' I',\n",
        "  ' need',\n",
        "  ' to',\n",
        "  ' know',\n",
        "  ' uh',\n",
        "  ' how',\n",
        "  ' do',\n",
        "  ' you',\n",
        "  ' feel',\n",
        "  ' about',\n",
        "  ' uh',\n",
        "  ' about',\n",
        "  ' sending',\n",
        "  ' uh',\n",
        "  ' an',\n",
        "  ' elderly',\n",
        "  ' uh',\n",
        "  ' family',\n",
        "  ' member',\n",
        "  ' to',\n",
        "  ' a',\n",
        "  ' nursing',\n",
        "  ' home',\n",
        "  '?'],\n",
        " 3: ['---B:  ',\n",
        "  ' Well',\n",
        "  ' of',\n",
        "  ' course',\n",
        "  ' it',\n",
        "  \" 's\",\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' it',\n",
        "  \" 's\",\n",
        "  ' one',\n",
        "  ' of',\n",
        "  ' the',\n",
        "  ' last',\n",
        "  ' few',\n",
        "  ' things',\n",
        "  ' in',\n",
        "  ' the',\n",
        "  ' world',\n",
        "  ' you',\n",
        "  \" 'd\",\n",
        "  ' ever',\n",
        "  ' want',\n",
        "  ' to',\n",
        "  ' do',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  '.',\n",
        "  ' Unless',\n",
        "  ' it',\n",
        "  \" 's\",\n",
        "  ' just',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' really',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' and',\n",
        "  ' uh',\n",
        "  ' for',\n",
        "  ' their',\n",
        "  ' uh',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' for',\n",
        "  ' their',\n",
        "  ' own',\n",
        "  ' good',\n",
        "  '.'],\n",
        " 4: ['---A:  ', ' Yes', '.'],\n",
        " 5: ['---A:  ', ' Yeah', '.'],\n",
        " 6: ['---B:  ',\n",
        "  ' I',\n",
        "  \" 'd\",\n",
        "  ' be',\n",
        "  ' very',\n",
        "  ' very',\n",
        "  ' careful',\n",
        "  ' and',\n",
        "  ' uh',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' checking',\n",
        "  ' them',\n",
        "  ' out',\n",
        "  '.'],\n",
        " 7: ['---B:  ', ' Uh', ' our'],\n",
        " 8: ['---B:  ',\n",
        "  ' had',\n",
        "  ' t-',\n",
        "  ' place',\n",
        "  ' my',\n",
        "  ' mother',\n",
        "  ' in',\n",
        "  ' a',\n",
        "  ' nursing',\n",
        "  ' home',\n",
        "  '.'],\n",
        " 9: ['---B:  ',\n",
        "  ' She',\n",
        "  ' had',\n",
        "  ' a',\n",
        "  ' rather',\n",
        "  ' massive',\n",
        "  ' stroke',\n",
        "  ' about',\n",
        "  ' uh',\n",
        "  ' about',\n",
        "  ' uh',\n",
        "  ' eight',\n",
        "  ' months',\n",
        "  ' ago',\n",
        "  ' I',\n",
        "  ' guess',\n",
        "  '.'],\n",
        " 10: ['---A:  ', ' Uh-huh', '.'],\n",
        " 11: ['---B:  ',\n",
        "  ' And',\n",
        "  ' uh',\n",
        "  ' we',\n",
        "  ' were',\n",
        "  ' I',\n",
        "  ' was',\n",
        "  ' fortunate',\n",
        "  ' in',\n",
        "  ' that',\n",
        "  ' I',\n",
        "  ' was',\n",
        "  ' personally',\n",
        "  ' acquainted',\n",
        "  ' with',\n",
        "  ' the',\n",
        "  ' uh',\n",
        "  ' people',\n",
        "  ' who',\n",
        "  ' uh',\n",
        "  ' ran',\n",
        "  ' the',\n",
        "  ' nursing',\n",
        "  ' home',\n",
        "  ' in',\n",
        "  ' our',\n",
        "  ' little',\n",
        "  ' hometown',\n",
        "  '.'],\n",
        " 12: ['---A:  ', ' Yeah', '.'],\n",
        " 13: ['---B:  ',\n",
        "  ' So',\n",
        "  ' I',\n",
        "  ' was',\n",
        "  ' very',\n",
        "  ' comfortable',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' in',\n",
        "  ' doing',\n",
        "  ' it',\n",
        "  ' when',\n",
        "  ' it',\n",
        "  ' got',\n",
        "  ' to',\n",
        "  ' the',\n",
        "  ' point',\n",
        "  ' that',\n",
        "  ' we',\n",
        "  ' had',\n",
        "  ' to',\n",
        "  ' do',\n",
        "  ' it',\n",
        "  '.'],\n",
        " 14: ['---B:  ', ' But', ' there', \" 's\"],\n",
        " 15: ['---B:  ',\n",
        "  ' well',\n",
        "  ' I',\n",
        "  ' had',\n",
        "  ' an',\n",
        "  ' occasion',\n",
        "  ' for',\n",
        "  ' my',\n",
        "  ' mother-in-law',\n",
        "  ' who',\n",
        "  ' had',\n",
        "  ' fell',\n",
        "  ' and',\n",
        "  ' needed',\n",
        "  ' to',\n",
        "  ' be',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' could',\n",
        "  ' not',\n",
        "  ' take',\n",
        "  ' care',\n",
        "  ' of',\n",
        "  ' herself',\n",
        "  ' anymore',\n",
        "  ' was',\n",
        "  ' confined',\n",
        "  ' to',\n",
        "  ' a',\n",
        "  ' nursing',\n",
        "  ' home',\n",
        "  ' for',\n",
        "  ' a',\n",
        "  ' while'],\n",
        " 16: ['---B:  ',\n",
        "  ' that',\n",
        "  ' was',\n",
        "  ' really',\n",
        "  ' not',\n",
        "  ' a',\n",
        "  ' very',\n",
        "  ' good',\n",
        "  ' experience',\n",
        "  '.'],\n",
        " 17: ['---B:  ',\n",
        "  ' Uh',\n",
        "  ' it',\n",
        "  ' had',\n",
        "  ' to',\n",
        "  ' be',\n",
        "  ' done',\n",
        "  ' in',\n",
        "  ' a',\n",
        "  ' hurry',\n",
        "  '.'],\n",
        " 18: ['---B:  ',\n",
        "  ' I',\n",
        "  ' mean',\n",
        "  ' we',\n",
        "  ' did',\n",
        "  \" n't\",\n",
        "  ' have',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' like',\n",
        "  ' six',\n",
        "  ' months',\n",
        "  ' to',\n",
        "  ' check',\n",
        "  ' all',\n",
        "  ' of',\n",
        "  ' these',\n",
        "  ' places',\n",
        "  ' out',\n",
        "  '.'],\n",
        " 19: ['---B:  ',\n",
        "  ' And',\n",
        "  ' it',\n",
        "  ' was',\n",
        "  ' really',\n",
        "  ' not',\n",
        "  ' not',\n",
        "  ' very',\n",
        "  ' good',\n",
        "  ' uh',\n",
        "  ' deal',\n",
        "  '.'],\n",
        " 20: ['---A:  ', ' Yeah', '.'],\n",
        " 21: ['---B:  ',\n",
        "  ' We',\n",
        "  ' were',\n",
        "  ' not',\n",
        "  ' really',\n",
        "  ' happy',\n",
        "  ' with',\n",
        "  ' nursing',\n",
        "  ' home',\n",
        "  ' that',\n",
        "  ' we',\n",
        "  ' finally',\n",
        "  ' had',\n",
        "  '.'],\n",
        " 22: ['---A:  ', ' Yeah', '.'],\n",
        " 23: ['---B:  ',\n",
        "  ' Fortunately',\n",
        "  ' she',\n",
        "  ' only',\n",
        "  ' had',\n",
        "  ' to',\n",
        "  ' stay',\n",
        "  ' a',\n",
        "  ' few',\n",
        "  ' weeks'],\n",
        " 24: ['---B:  ',\n",
        "  ' and',\n",
        "  ' she',\n",
        "  ' was',\n",
        "  ' able',\n",
        "  ' to',\n",
        "  ' to',\n",
        "  ' return',\n",
        "  ' to',\n",
        "  ' her',\n",
        "  ' apartment',\n",
        "  ' again',\n",
        "  '.'],\n",
        " 25: ['---B:  ',\n",
        "  ' But',\n",
        "  ' it',\n",
        "  \" 's\",\n",
        "  ' really',\n",
        "  ' a',\n",
        "  ' big',\n",
        "  ' uh',\n",
        "  ' big',\n",
        "  ' uh',\n",
        "  ' decision',\n",
        "  ' as',\n",
        "  ' to',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' when',\n",
        "  ' to',\n",
        "  ' do',\n",
        "  ' it',\n",
        "  '.'],\n",
        " 26: ['---A:  ', ' Yeah', '.'],\n",
        " 27: ['---B:  ',\n",
        "  ' You',\n",
        "  ' know',\n",
        "  ' is',\n",
        "  ' there',\n",
        "  ' something',\n",
        "  ' else',\n",
        "  ' we',\n",
        "  ' could',\n",
        "  ' have',\n",
        "  ' done',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' in',\n",
        "  ' checking',\n",
        "  ' out',\n",
        "  ' all',\n",
        "  ' the',\n",
        "  ' places',\n",
        "  ' that',\n",
        "  ' uh',\n",
        "  ' might',\n",
        "  ' be',\n",
        "  ' available',\n",
        "  '.'],\n",
        " 28: ['---B:  ',\n",
        "  ' Of',\n",
        "  ' course',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' there',\n",
        "  \" 's\",\n",
        "  ' not',\n",
        "  ' one',\n",
        "  ' on',\n",
        "  ' every',\n",
        "  ' corner',\n",
        "  ' especially',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' smaller',\n",
        "  ' areas',\n",
        "  ' smaller',\n",
        "  ' towns',\n",
        "  '.'],\n",
        " 29: ['---A:  ', ' Yeah', '.'],\n",
        " 30: ['---A:  ', ' Uh-huh', '.'],\n",
        " 31: ['---A:  ', ' Uh-huh', '.'],\n",
        " 32: ['---A:  ', ' Yeah', '.'],\n",
        " 33: ['---A:  ',\n",
        "  ' Probably',\n",
        "  ' the',\n",
        "  ' hardest',\n",
        "  ' thing',\n",
        "  ' in',\n",
        "  ' in',\n",
        "  ' my',\n",
        "  ' family',\n",
        "  ' uh',\n",
        "  ' my',\n",
        "  ' grandmother',\n",
        "  ' she',\n",
        "  ' had',\n",
        "  ' to',\n",
        "  ' be',\n",
        "  ' put',\n",
        "  ' in',\n",
        "  ' a',\n",
        "  ' nursing',\n",
        "  ' home'],\n",
        " 34: ['---A:  ',\n",
        "  ' and',\n",
        "  ' um',\n",
        "  ' she',\n",
        "  ' had',\n",
        "  ' used',\n",
        "  ' the',\n",
        "  ' walker',\n",
        "  ' for',\n",
        "  ' for',\n",
        "  ' quite',\n",
        "  ' some',\n",
        "  ' time',\n",
        "  ' probably',\n",
        "  ' about',\n",
        "  ' six',\n",
        "  ' to',\n",
        "  ' nine',\n",
        "  ' months',\n",
        "  '.'],\n",
        " 35: ['---A:  ', ' And', ' um', ' she', ' had', ' a', ' fall'],\n",
        " 36: ['---A:  ',\n",
        "  ' and',\n",
        "  ' uh',\n",
        "  ' finally',\n",
        "  ' uh',\n",
        "  ' she',\n",
        "  ' had',\n",
        "  ' Parkinson',\n",
        "  \" 's\",\n",
        "  ' disease'],\n",
        " 37: ['---B:  ', ' Oh', '.'],\n",
        " 38: ['---A:  ',\n",
        "  ' and',\n",
        "  ' it',\n",
        "  ' got',\n",
        "  ' so',\n",
        "  ' much',\n",
        "  ' that',\n",
        "  ' she',\n",
        "  ' could',\n",
        "  ' not',\n",
        "  ' take',\n",
        "  ' care',\n",
        "  ' of',\n",
        "  ' her',\n",
        "  ' house',\n",
        "  '.'],\n",
        " 39: ['---B:  ', ' Right', '.'],\n",
        " 40: ['---A:  ', ' Then', ' she', ' lived', ' in', ' an', ' apartment'],\n",
        " 41: ['---A:  ',\n",
        "  ' and',\n",
        "  ' uh',\n",
        "  ' that',\n",
        "  ' was',\n",
        "  ' even',\n",
        "  ' harder',\n",
        "  ' actually',\n",
        "  '.'],\n",
        " 42: ['---B:  ', ' Uh-huh', '.'],\n",
        " 43: ['---B:  ', ' Uh-huh', '.'],\n",
        " 44: ['---A:  ',\n",
        "  ' Because',\n",
        "  ' it',\n",
        "  ' was',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' it',\n",
        "  ' was',\n",
        "  ' just',\n",
        "  ' a',\n",
        "  ' change',\n",
        "  ' of',\n",
        "  ' change',\n",
        "  ' of',\n",
        "  ' location'],\n",
        " 45: ['---A:  ',\n",
        "  ' and',\n",
        "  ' it',\n",
        "  ' was',\n",
        "  ' very',\n",
        "  ' disturbing',\n",
        "  ' for',\n",
        "  ' her',\n",
        "  ' because',\n",
        "  ' she',\n",
        "  ' had',\n",
        "  ' been',\n",
        "  ' so',\n",
        "  ' used',\n",
        "  ' to',\n",
        "  ' traveling',\n",
        "  '.'],\n",
        " 46: ['---B:  ', ' Yes', '.'],\n",
        " 47: ['---A:  ',\n",
        "  ' I',\n",
        "  ' mean',\n",
        "  ' she',\n",
        "  ' tr-',\n",
        "  ' she',\n",
        "  ' had',\n",
        "  ' she',\n",
        "  ' had',\n",
        "  ' children',\n",
        "  ' all',\n",
        "  ' across',\n",
        "  ' the',\n",
        "  ' United',\n",
        "  ' States'],\n",
        " 48: ['---B:  ', ' Uh-huh'],\n",
        " 49: ['---A:  ',\n",
        "  ' and',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' she',\n",
        "  ' spent',\n",
        "  ' nine',\n",
        "  ' months',\n",
        "  ' out',\n",
        "  ' of',\n",
        "  ' the',\n",
        "  ' year',\n",
        "  ' just',\n",
        "  ' visiting',\n",
        "  ' her',\n",
        "  ' children',\n",
        "  '.'],\n",
        " 50: ['---B:  ', ' Right', '.'],\n",
        " 51: ['---B:  ', ' Uh-huh', '.'],\n",
        " 52: ['---A:  ',\n",
        "  ' And',\n",
        "  ' um',\n",
        "  ' that',\n",
        "  ' was',\n",
        "  ' pretty',\n",
        "  ' heart-rending',\n",
        "  ' for',\n",
        "  ' her',\n",
        "  '.'],\n",
        " 53: ['---B:  ', ' I', ' can', ' imagine', '.'],\n",
        " 54: ['---A:  ',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' when',\n",
        "  ' she',\n",
        "  ' finally',\n",
        "  ' came',\n",
        "  ' to',\n",
        "  ' the',\n",
        "  ' realization',\n",
        "  ' that',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' no',\n",
        "  ' I',\n",
        "  ' can',\n",
        "  ' not',\n",
        "  ' I',\n",
        "  ' can',\n",
        "  ' not',\n",
        "  ' take',\n",
        "  ' care',\n",
        "  ' of',\n",
        "  ' myself',\n",
        "  '.'],\n",
        " 55: ['---B:  ', ' Uh-huh', '.'],\n",
        " 56: ['---B:  ', ' That', \" 's\", ' tough', '.'],\n",
        " 57: ['---B:  ', ' That', \" 's\", ' tough', '.'],\n",
        " 58: ['---A:  ', ' Yeah', '.'],\n",
        " 59: ['---A:  ',\n",
        "  ' I',\n",
        "  ' mean',\n",
        "  ' for',\n",
        "  ' somebody',\n",
        "  ' who',\n",
        "  ' is',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' for',\n",
        "  ' most',\n",
        "  ' of',\n",
        "  ' their',\n",
        "  ' life',\n",
        "  ' has',\n",
        "  ' has',\n",
        "  ' uh',\n",
        "  ' not',\n",
        "  ' just',\n",
        "  ' merely',\n",
        "  ' had',\n",
        "  ' a',\n",
        "  ' farm',\n",
        "  ' but',\n",
        "  ' had',\n",
        "  ' ten',\n",
        "  ' children',\n",
        "  ' had',\n",
        "  ' a',\n",
        "  ' farm',\n",
        "  ' ran',\n",
        "  ' everything',\n",
        "  ' because',\n",
        "  ' her',\n",
        "  ' husband',\n",
        "  ' was',\n",
        "  ' away',\n",
        "  ' in',\n",
        "  ' the',\n",
        "  ' coal',\n",
        "  ' mines',\n",
        "  '.'],\n",
        " 60: ['---B:  ', ' Uh-huh', '.'],\n",
        " 61: ['---B:  ', ' Uh-huh', '.'],\n",
        " 62: ['---A:  ',\n",
        "  ' And',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' facing',\n",
        "  ' that',\n",
        "  ' situation',\n",
        "  ' it',\n",
        "  \" 's\",\n",
        "  ' it',\n",
        "  \" 's\",\n",
        "  ' quite',\n",
        "  ' a',\n",
        "  ' dilemma',\n",
        "  '.'],\n",
        " 63: ['---B:  ', ' Yes', '.'],\n",
        " 64: ['---A:  ', ' I', ' think'],\n",
        " 65: ['---B:  ', ' my', ' mother', ' excuse', ' me', '.'],\n",
        " 66: ['---B:  ', ' Go', ' ahead', '.'],\n",
        " 67: ['---A:  ', ' Yeah', '.'],\n",
        " 68: ['---A:  ', ' Well', ' my', ' uh', ' my', ' uh'],\n",
        " 69: ['---A:  ',\n",
        "  ' probably',\n",
        "  ' one',\n",
        "  ' of',\n",
        "  ' the',\n",
        "  ' biggest',\n",
        "  ' decisions',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' that',\n",
        "  ' was',\n",
        "  ' very',\n",
        "  ' strengthening',\n",
        "  ' for',\n",
        "  ' our',\n",
        "  ' family',\n",
        "  ' was',\n",
        "  ' rather',\n",
        "  ' than',\n",
        "  ' have',\n",
        "  ' one',\n",
        "  ' child',\n",
        "  ' make',\n",
        "  ' that',\n",
        "  ' decision',\n",
        "  ' than',\n",
        "  ' just',\n",
        "  ' delegate',\n",
        "  ' it',\n",
        "  '.'],\n",
        " 70: ['---B:  ', ' Uh-huh', '.'],\n",
        " 71: ['---A:  ',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' that',\n",
        "  ' they',\n",
        "  ' they',\n",
        "  ' had',\n",
        "  ' a',\n",
        "  ' great',\n",
        "  ' deal',\n",
        "  ' of',\n",
        "  ' um'],\n",
        " 72: ['---A:  ',\n",
        "  ' all',\n",
        "  ' the',\n",
        "  ' brothers',\n",
        "  ' and',\n",
        "  ' sisters',\n",
        "  ' got',\n",
        "  ' together'],\n",
        " 73: ['---A:  ',\n",
        "  ' and',\n",
        "  ' they',\n",
        "  ' actually',\n",
        "  ' had',\n",
        "  ' a',\n",
        "  ' conference',\n",
        "  '.'],\n",
        " 74: ['---B:  ', ' That', \" 's\", ' great', '.'],\n",
        " 75: ['---A:  ',\n",
        "  ' And',\n",
        "  ' I',\n",
        "  ' mean',\n",
        "  ' it',\n",
        "  ' was',\n",
        "  ' just',\n",
        "  ' it',\n",
        "  ' was',\n",
        "  ' probably',\n",
        "  ' one',\n",
        "  ' of',\n",
        "  ' the',\n",
        "  ' most',\n",
        "  ' strengthening',\n",
        "  ' things',\n",
        "  ' for',\n",
        "  ' our',\n",
        "  ' family',\n",
        "  ' getting',\n",
        "  ' down',\n",
        "  ' together',\n",
        "  ' and',\n",
        "  ' doing',\n",
        "  ' that',\n",
        "  '.'],\n",
        " 76: ['---B:  ', ' That', \" 's\", ' right', '.'],\n",
        " 77: ['---A:  ',\n",
        "  ' And',\n",
        "  ' and',\n",
        "  ' just',\n",
        "  ' the',\n",
        "  ' children',\n",
        "  ' were',\n",
        "  ' involved',\n",
        "  ' in',\n",
        "  ' the',\n",
        "  ' decision',\n",
        "  ' because',\n",
        "  ' it',\n",
        "  ' involved',\n",
        "  ' just',\n",
        "  ' them',\n",
        "  '.',\n",
        "  ' And',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' making',\n",
        "  ' that',\n",
        "  ' decision',\n",
        "  ' and',\n",
        "  ' then',\n",
        "  ' finding',\n",
        "  ' a',\n",
        "  ' place'],\n",
        " 78: ['---B:  ', ' Right', '.'],\n",
        " 79: ['---B:  ', ' Yeah', '.'],\n",
        " 80: ['---A:  ',\n",
        "  ' and',\n",
        "  ' everybody',\n",
        "  ' had',\n",
        "  ' duties',\n",
        "  ' to',\n",
        "  ' perform',\n",
        "  '.'],\n",
        " 81: ['---B:  ', ' Uh-huh', '.'],\n",
        " 82: ['---A:  ',\n",
        "  ' You',\n",
        "  ' know',\n",
        "  ' whether',\n",
        "  ' it',\n",
        "  ' was',\n",
        "  ' just',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' giving',\n",
        "  ' money',\n",
        "  ' or',\n",
        "  ' whether',\n",
        "  ' it',\n",
        "  ' was',\n",
        "  ' actually',\n",
        "  ' taking',\n",
        "  ' part',\n",
        "  ' in',\n",
        "  ' a',\n",
        "  ' lot',\n",
        "  ' of',\n",
        "  ' the',\n",
        "  ' decision',\n",
        "  ' making',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' like',\n",
        "  ' finding',\n",
        "  ' a',\n",
        "  ' proper',\n",
        "  ' nursing',\n",
        "  ' home',\n",
        "  '.'],\n",
        " 83: ['---B:  ', ' Uh-huh', '.'],\n",
        " 84: ['---B:  ', ' Yep', '.'],\n",
        " 85: ['---B:  ', ' You', ' were', ' very', ' fortunate', '.'],\n",
        " 86: ['---A:  ', ' And', ' they'],\n",
        " 87: ['---A:  ', ' I', ' know', '.'],\n",
        " 88: ['---A:  ',\n",
        "  ' They',\n",
        "  ' and',\n",
        "  ' well',\n",
        "  ' they',\n",
        "  ' had',\n",
        "  ' well',\n",
        "  ' they',\n",
        "  ' had',\n",
        "  ' they',\n",
        "  ' had',\n",
        "  ' seen',\n",
        "  ' it',\n",
        "  ' coming',\n",
        "  '.'],\n",
        " 89: ['---B:  ', ' Uh-huh', '.'],\n",
        " 90: ['---A:  ', ' So', ' so'],\n",
        " 91: ['---A:  ', ' I', ' mean', ' it'],\n",
        " 92: ['---A:  ',\n",
        "  ' I',\n",
        "  ' mean',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' har-',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' truly',\n",
        "  ' wish',\n",
        "  ' that',\n",
        "  ' if',\n",
        "  ' something',\n",
        "  ' like',\n",
        "  ' that',\n",
        "  ' were',\n",
        "  ' to',\n",
        "  ' happen',\n",
        "  ' that',\n",
        "  ' my',\n",
        "  ' children',\n",
        "  ' would',\n",
        "  ' do',\n",
        "  ' something',\n",
        "  ' like',\n",
        "  ' that',\n",
        "  ' for',\n",
        "  ' me',\n",
        "  '.'],\n",
        " 93: ['---B:  ', ' Uh-huh', '.'],\n",
        " 94: ['---B:  ', ' Uh-huh', '.'],\n",
        " 95: ['---B:  ', ' Absolutely', '.'],\n",
        " 96: ['---B:  ',\n",
        "  ' Unfortunately',\n",
        "  ' a',\n",
        "  ' lot',\n",
        "  ' of',\n",
        "  ' times',\n",
        "  ' it',\n",
        "  ' responsibilities',\n",
        "  ' like',\n",
        "  ' that',\n",
        "  ' seem',\n",
        "  ' to',\n",
        "  ' fall',\n",
        "  ' to',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' maybe',\n",
        "  ' one',\n",
        "  ' child',\n",
        "  ' in',\n",
        "  ' the',\n",
        "  ' whole',\n",
        "  ' family',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  '.'],\n",
        " 97: ['---A:  ', ' Yeah', '.'],\n",
        " 98: ['---A:  ', ' Yeah', '.'],\n",
        " 99: ['---A:  ', ' Well', ' we', ' we'],\n",
        " 100: ['---B:  ',\n",
        "  ' And',\n",
        "  ' uh',\n",
        "  ' it',\n",
        "  \" 's\",\n",
        "  ' usually',\n",
        "  ' not',\n",
        "  ' a',\n",
        "  ' very',\n",
        "  ' smooth',\n",
        "  ' smooth',\n",
        "  ' thing',\n",
        "  '.'],\n",
        " 101: ['---A:  ', ' Yeah', '.'],\n",
        " 102: ['---B:  ',\n",
        "  ' We',\n",
        "  ' were',\n",
        "  ' I',\n",
        "  ' was',\n",
        "  ' lucky',\n",
        "  ' too',\n",
        "  ' that',\n",
        "  ' I',\n",
        "  ' only',\n",
        "  ' have',\n",
        "  ' one',\n",
        "  ' brother',\n",
        "  '.'],\n",
        " 103: ['---A:  ', ' Uh-huh', '.'],\n",
        " 104: ['---B:  ',\n",
        "  ' And',\n",
        "  ' uh',\n",
        "  ' fortunately',\n",
        "  ' we',\n",
        "  ' agreed',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' on',\n",
        "  ' exactly',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' what',\n",
        "  ' we',\n",
        "  ' thought',\n",
        "  ' should',\n",
        "  ' be',\n",
        "  ' done',\n",
        "  '.'],\n",
        " 105: ['---B:  ',\n",
        "  ' My',\n",
        "  ' mother',\n",
        "  ' also',\n",
        "  ' was',\n",
        "  ' very',\n",
        "  ' very',\n",
        "  ' independent',\n",
        "  '.'],\n",
        " 106: ['---B:  ',\n",
        "  ' She',\n",
        "  ' had',\n",
        "  ' her',\n",
        "  ' own',\n",
        "  ' still',\n",
        "  ' had',\n",
        "  ' her',\n",
        "  ' own',\n",
        "  ' little',\n",
        "  ' house',\n",
        "  ' and',\n",
        "  ' still',\n",
        "  ' driving',\n",
        "  ' her',\n",
        "  ' own',\n",
        "  ' car',\n",
        "  ' at',\n",
        "  ' age',\n",
        "  ' eighty-three',\n",
        "  '.'],\n",
        " 107: ['---A:  ', ' Yeah', '.'],\n",
        " 108: ['---B:  ',\n",
        "  ' We',\n",
        "  ' were',\n",
        "  ' lucky',\n",
        "  ' in',\n",
        "  ' that',\n",
        "  ' in',\n",
        "  ' one',\n",
        "  ' respect',\n",
        "  ' in',\n",
        "  ' that',\n",
        "  ' after',\n",
        "  ' she',\n",
        "  ' had',\n",
        "  ' her',\n",
        "  ' stroke',\n",
        "  ' she',\n",
        "  ' was',\n",
        "  \" n't\",\n",
        "  ' really',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' really',\n",
        "  ' much',\n",
        "  ' aware',\n",
        "  ' of',\n",
        "  ' what',\n",
        "  ' was',\n",
        "  ' going',\n",
        "  ' on',\n",
        "  '.'],\n",
        " 109: ['---A:  ', ' Uh-huh', '.'],\n",
        " 110: ['---B:  ',\n",
        "  ' That',\n",
        "  ' nursing',\n",
        "  ' home',\n",
        "  ' life',\n",
        "  ' would',\n",
        "  ' not',\n",
        "  ' have',\n",
        "  ' been',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' anything',\n",
        "  ' of',\n",
        "  ' her',\n",
        "  ' choosing'],\n",
        " 111: ['---B:  ',\n",
        "  ' of',\n",
        "  ' course',\n",
        "  ' she',\n",
        "  ' would',\n",
        "  ' she',\n",
        "  ' would',\n",
        "  ' not',\n",
        "  ' have',\n",
        "  ' been',\n",
        "  ' happy',\n",
        "  ' there',\n",
        "  ' at',\n",
        "  ' all',\n",
        "  '.'],\n",
        " 112: ['---A:  ', ' Um', '.'],\n",
        " 113: ['---B:  ',\n",
        "  ' But',\n",
        "  ' as',\n",
        "  ' it',\n",
        "  ' turned',\n",
        "  ' out',\n",
        "  ' the',\n",
        "  ' stroke',\n",
        "  ' took',\n",
        "  ' care',\n",
        "  ' of',\n",
        "  ' that',\n",
        "  ' concern',\n",
        "  ' for',\n",
        "  ' us',\n",
        "  '.'],\n",
        " 114: ['---A:  ', ' Yeah', '.'],\n",
        " 115: ['---A:  ', ' Yeah', '.'],\n",
        " 116: ['---A:  ',\n",
        "  ' Well',\n",
        "  ' with',\n",
        "  ' my',\n",
        "  ' with',\n",
        "  ' my',\n",
        "  ' grandmother',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' it',\n",
        "  ' was',\n",
        "  ' it',\n",
        "  ' was',\n",
        "  ' such',\n",
        "  ' that',\n",
        "  ' uh',\n",
        "  ' that',\n",
        "  ' she',\n",
        "  ' did',\n",
        "  ' not',\n",
        "  ' have',\n",
        "  ' the',\n",
        "  ' problem',\n",
        "  ' with'],\n",
        " 117: ['---A:  ', ' she', ' was', ' very', ' well', ' aware'],\n",
        " 118: ['---A:  ',\n",
        "  ' and',\n",
        "  ' her',\n",
        "  ' daughter',\n",
        "  ' came',\n",
        "  ' and',\n",
        "  ' visited',\n",
        "  ' her'],\n",
        " 119: ['---B:  ', ' Uh-huh', '.'],\n",
        " 120: ['---A:  ',\n",
        "  ' at',\n",
        "  ' least',\n",
        "  ' her',\n",
        "  ' daughter',\n",
        "  ' came',\n",
        "  ' and',\n",
        "  ' visited',\n",
        "  ' her'],\n",
        " 121: ['---A:  ',\n",
        "  ' and',\n",
        "  ' also',\n",
        "  ' her',\n",
        "  ' several',\n",
        "  ' grandchildren',\n",
        "  ' came',\n",
        "  ' and',\n",
        "  ' visited',\n",
        "  ' her',\n",
        "  ' every',\n",
        "  ' day',\n",
        "  '.'],\n",
        " 122: ['---B:  ', ' Uh-huh', '.'],\n",
        " 123: ['---B:  ', ' Uh-huh', '.'],\n",
        " 124: ['---B:  ', ' That', \" 's\", ' great', '.'],\n",
        " 125: ['---A:  ',\n",
        "  ' And',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' that',\n",
        "  ' when',\n",
        "  ' she',\n",
        "  ' passed',\n",
        "  ' away',\n",
        "  ' it',\n",
        "  ' was',\n",
        "  ' probably',\n",
        "  ' one',\n",
        "  ' of',\n",
        "  ' the',\n",
        "  ' greatest'],\n",
        " 126: ['---A:  ', ' um', ' I', ' I', ' I', ' think', ' it', ' would', ' be'],\n",
        " 127: ['---A:  ',\n",
        "  ' it',\n",
        "  ' was',\n",
        "  ' more',\n",
        "  ' of',\n",
        "  ' a',\n",
        "  ' relief',\n",
        "  ' for',\n",
        "  ' her',\n",
        "  '.'],\n",
        " 128: ['---B:  ', ' Uh-huh', '.'],\n",
        " 129: ['---B:  ', ' Sure', '.'],\n",
        " 130: ['---A:  ', ' And', ' um'],\n",
        " 131: ['---A:  ',\n",
        "  ' I',\n",
        "  ' mean',\n",
        "  ' but',\n",
        "  ' she',\n",
        "  ' was',\n",
        "  ' truly',\n",
        "  ' she',\n",
        "  ' was',\n",
        "  ' truly',\n",
        "  ' aware',\n",
        "  '.'],\n",
        " 132: ['---A:  ',\n",
        "  ' I',\n",
        "  ' mean',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' di-',\n",
        "  ' I',\n",
        "  ' do',\n",
        "  \" n't\",\n",
        "  ' know',\n",
        "  ' how',\n",
        "  ' I',\n",
        "  ' would',\n",
        "  ' how',\n",
        "  ' I',\n",
        "  ' would',\n",
        "  ' deal',\n",
        "  ' if',\n",
        "  ' one',\n",
        "  ' of',\n",
        "  ' my',\n",
        "  ' parents',\n",
        "  ' came',\n",
        "  ' with',\n",
        "  ' with',\n",
        "  ' Alzheimer',\n",
        "  \" 's\",\n",
        "  '.',\n",
        "  ' or',\n",
        "  ' something',\n",
        "  ' like',\n",
        "  ' that',\n",
        "  ' which',\n",
        "  ' is',\n",
        "  ' which',\n",
        "  ' is',\n",
        "  ' far',\n",
        "  ' more',\n",
        "  ' devastating',\n",
        "  '.'],\n",
        " 133: ['---B:  ', ' Uh-huh', '.'],\n",
        " 134: ['---B:  ', ' That', ' would', ' be', ' tough', '.'],\n",
        " 135: ['---B:  ', ' Yes', '.'],\n",
        " 136: ['---B:  ', ' Absolutely', '.'],\n",
        " 137: ['---A:  ',\n",
        "  ' And',\n",
        "  ' um',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' that',\n",
        "  ' what',\n",
        "  ' one',\n",
        "  ' thing',\n",
        "  ' that',\n",
        "  ' they',\n",
        "  ' were',\n",
        "  ' concerned',\n",
        "  ' probably',\n",
        "  ' was',\n",
        "  ' the',\n",
        "  ' fact',\n",
        "  ' it',\n",
        "  ' was',\n",
        "  \" n't\",\n",
        "  ' necessarily',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' like',\n",
        "  ' the',\n",
        "  ' quantity',\n",
        "  ' of',\n",
        "  ' care',\n",
        "  ' but',\n",
        "  ' the',\n",
        "  ' quality',\n",
        "  ' of',\n",
        "  ' care',\n",
        "  '.'],\n",
        " 138: ['---B:  ', ' Uh-huh', '.'],\n",
        " 139: ['---B:  ', ' Yes', '.'],\n",
        " 140: ['---A:  ',\n",
        "  ' That',\n",
        "  ' the',\n",
        "  ' people',\n",
        "  ' that',\n",
        "  ' worked',\n",
        "  ' there',\n",
        "  ' were',\n",
        "  ' very',\n",
        "  ' were',\n",
        "  ' very',\n",
        "  ' interested',\n",
        "  ' that',\n",
        "  ' to',\n",
        "  ' make',\n",
        "  ' it',\n",
        "  ' as',\n",
        "  ' close',\n",
        "  ' a',\n",
        "  ' home',\n",
        "  ' environment',\n",
        "  ' as',\n",
        "  ' possible',\n",
        "  '.'],\n",
        " 141: ['---B:  ', ' Right', '.'],\n",
        " 142: ['---B:  ', ' Uh-huh', '.'],\n",
        " 143: ['---B:  ', ' Uh-huh', '.'],\n",
        " 144: ['---B:  ', ' Yes', '.'],\n",
        " 145: ['---B:  ', ' It', ' would'],\n",
        " 146: ['---A:  ',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' for',\n",
        "  ' myself',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' see',\n",
        "  ' that',\n",
        "  ' as',\n",
        "  ' probably',\n",
        "  ' the',\n",
        "  ' the',\n",
        "  ' what',\n",
        "  ' everything',\n",
        "  ' would',\n",
        "  ' hinge',\n",
        "  ' upon',\n",
        "  '.'],\n",
        " 147: ['---B:  ', ' Oh'],\n",
        " 148: ['---A:  ', ' Is', ' it'],\n",
        " 149: ['---A:  ',\n",
        "  ' how',\n",
        "  ' close',\n",
        "  ' is',\n",
        "  ' it',\n",
        "  ' to',\n",
        "  ' a',\n",
        "  ' home',\n",
        "  ' environment',\n",
        "  '.'],\n",
        " 150: ['---B:  ', ' Yes', '.'],\n",
        " 151: ['---B:  ', ' That', \" 's\", ' right', '.'],\n",
        " 152: ['---A:  ',\n",
        "  ' That',\n",
        "  \" 's\",\n",
        "  ' the',\n",
        "  ' that',\n",
        "  \" 's\",\n",
        "  ' probably',\n",
        "  ' the',\n",
        "  ' major',\n",
        "  ' question',\n",
        "  '.'],\n",
        " 153: ['---B:  ',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' that',\n",
        "  ' great',\n",
        "  ' strides',\n",
        "  ' are',\n",
        "  ' being',\n",
        "  ' made',\n",
        "  ' nowadays',\n",
        "  ' in',\n",
        "  ' in',\n",
        "  ' caring',\n",
        "  ' for',\n",
        "  ' the',\n",
        "  ' elderly',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' in',\n",
        "  ' several',\n",
        "  ' in',\n",
        "  ' a',\n",
        "  ' in',\n",
        "  ' a',\n",
        "  ' whole',\n",
        "  ' lot',\n",
        "  ' of',\n",
        "  ' areas',\n",
        "  '.'],\n",
        " 154: ['---A:  ', ' Yeah', '.'],\n",
        " 155: ['---A:  ', ' Yeah', '.'],\n",
        " 156: ['---B:  ',\n",
        "  ' Just',\n",
        "  ' people',\n",
        "  ' are',\n",
        "  ' of',\n",
        "  ' course',\n",
        "  ' populations',\n",
        "  ' getting',\n",
        "  ' older',\n",
        "  '.'],\n",
        " 157: ['---A:  ', ' Yeah', '.'],\n",
        " 158: ['---A:  ',\n",
        "  ' You',\n",
        "  ' know',\n",
        "  ' it',\n",
        "  \" 's\",\n",
        "  ' it',\n",
        "  \" 's\",\n",
        "  ' interesting',\n",
        "  ' that',\n",
        "  ' that',\n",
        "  ' a',\n",
        "  ' lot',\n",
        "  ' the',\n",
        "  ' population',\n",
        "  ' of',\n",
        "  ' the',\n",
        "  ' United',\n",
        "  ' States',\n",
        "  ' is',\n",
        "  ' changing',\n",
        "  ' because',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' uh',\n",
        "  ' now',\n",
        "  ' that',\n",
        "  ' so',\n",
        "  ' many',\n",
        "  ' more',\n",
        "  ' minorities',\n",
        "  ' where',\n",
        "  ' they',\n",
        "  ' have',\n",
        "  ' had',\n",
        "  ' extended',\n",
        "  ' families',\n",
        "  ' for',\n",
        "  ' such',\n",
        "  ' a',\n",
        "  ' long',\n",
        "  ' time',\n",
        "  '.'],\n",
        " 159: ['---B:  ', ' Uh-huh', '.'],\n",
        " 160: ['---A:  ',\n",
        "  ' Um',\n",
        "  ' matter',\n",
        "  ' of',\n",
        "  ' fact',\n",
        "  ' in',\n",
        "  ' the',\n",
        "  ' United',\n",
        "  ' States',\n",
        "  ' we',\n",
        "  ' used',\n",
        "  ' to',\n",
        "  ' have',\n",
        "  ' extended',\n",
        "  ' families',\n",
        "  '.'],\n",
        " 161: ['---B:  ', ' Uh-huh'],\n",
        " 162: ['---A:  ', ' It', ' was', \" n't\"],\n",
        " 163: ['---B:  ', ' true', '.'],\n",
        " 164: ['---A:  ',\n",
        "  ' But',\n",
        "  ' I',\n",
        "  ' guess',\n",
        "  ' as',\n",
        "  ' we',\n",
        "  ' become',\n",
        "  ' more',\n",
        "  ' industrialized',\n",
        "  ' and',\n",
        "  ' more',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' less',\n",
        "  ' in',\n",
        "  ' a',\n",
        "  ' rural',\n",
        "  ' situation',\n",
        "  ' we',\n",
        "  ' we',\n",
        "  ' do',\n",
        "  \" n't\",\n",
        "  ' we',\n",
        "  ' we',\n",
        "  ' we',\n",
        "  ' choose',\n",
        "  ' not',\n",
        "  ' to',\n",
        "  ' deal',\n",
        "  ' with',\n",
        "  ' the',\n",
        "  ' extended',\n",
        "  ' family',\n",
        "  ' because',\n",
        "  ' we',\n",
        "  ' feel',\n",
        "  ' it',\n",
        "  \" 's\",\n",
        "  ' kind',\n",
        "  ' of',\n",
        "  ' cumbersome',\n",
        "  ' when',\n",
        "  ' in',\n",
        "  ' reality',\n",
        "  ' it',\n",
        "  ' makes',\n",
        "  ' things',\n",
        "  ' much',\n",
        "  ' much',\n",
        "  ' easier',\n",
        "  '.'],\n",
        " 165: ['---B:  ', ' Yes', ' um', '.'],\n",
        " 166: ['---B:  ', ' Uh-huh', '.'],\n",
        " 167: ['---B:  ', ' Uh-huh', '.'],\n",
        " 168: ['---B:  ', ' That', \" 's\", ' right', '.'],\n",
        " 169: ['---B:  ', ' Sure', '.'],\n",
        " 170: ['---B:  ', ' Absolutely', '.'],\n",
        " 171: ['---B:  ',\n",
        "  ' And',\n",
        "  ' people',\n",
        "  ' things',\n",
        "  ' are',\n",
        "  ' scattered',\n",
        "  ' so',\n",
        "  ' much',\n",
        "  ' nowadays',\n",
        "  '.'],\n",
        " 172: ['---A:  ', ' Uh', '.', ' Yeah', '.'],\n",
        " 173: ['---A:  ', ' Yeah', '.'],\n",
        " 174: ['---A:  ',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' that',\n",
        "  ' perhaps',\n",
        "  ' perhaps',\n",
        "  ' the',\n",
        "  ' extended',\n",
        "  ' family',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' that',\n",
        "  ' it',\n",
        "  ' maybe',\n",
        "  ' one',\n",
        "  ' of',\n",
        "  ' the',\n",
        "  ' solutions',\n",
        "  ' to',\n",
        "  ' a',\n",
        "  ' lot',\n",
        "  ' of',\n",
        "  ' things',\n",
        "  ' even',\n",
        "  ' child',\n",
        "  ' care',\n",
        "  '.'],\n",
        " 175: ['---B:  ', ' Yes', '.'],\n",
        " 176: ['---A:  ',\n",
        "  ' You',\n",
        "  ' know',\n",
        "  ' I',\n",
        "  ' mean',\n",
        "  ' of',\n",
        "  ' course',\n",
        "  ' there',\n",
        "  ' there',\n",
        "  ' comes',\n",
        "  ' other',\n",
        "  ' issues',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' whether',\n",
        "  ' or',\n",
        "  ' not',\n",
        "  ' any',\n",
        "  ' of',\n",
        "  ' the',\n",
        "  ' grandparents',\n",
        "  ' whether',\n",
        "  ' we',\n",
        "  ' feel',\n",
        "  ' like',\n",
        "  ' are',\n",
        "  ' going',\n",
        "  ' to',\n",
        "  ' be',\n",
        "  ' a',\n",
        "  ' good',\n",
        "  ' they',\n",
        "  \" 're\",\n",
        "  ' going',\n",
        "  ' to',\n",
        "  ' be',\n",
        "  ' a',\n",
        "  ' good',\n",
        "  ' caretaker',\n",
        "  ' for',\n",
        "  ' our',\n",
        "  ' children',\n",
        "  '.'],\n",
        " 177: ['---B:  ', ' Yes'],\n",
        " 178: ['---A:  ', ' But'],\n",
        " 179: ['---B:  ', ' just', ' because', ' they', \" 're\", ' grandparents', '.'],\n",
        " 180: ['---A:  ',\n",
        "  ' I',\n",
        "  ' mean',\n",
        "  ' they',\n",
        "  ' raised',\n",
        "  ' us',\n",
        "  ' after',\n",
        "  ' all',\n",
        "  '.'],\n",
        " 181: ['---B:  ', ' Yeah', '.'],\n",
        " 182: ['---B:  ',\n",
        "  ' Just',\n",
        "  ' because',\n",
        "  ' they',\n",
        "  \" 're\",\n",
        "  ' grandparents',\n",
        "  ' that',\n",
        "  ' does',\n",
        "  \" n't\",\n",
        "  ' automatically',\n",
        "  ' make',\n",
        "  ' them',\n",
        "  ' a',\n",
        "  ' good',\n",
        "  ' child',\n",
        "  ' carer',\n",
        "  '.'],\n",
        " 183: ['---A:  ', ' Yeah', '.'],\n",
        " 184: ['---A:  ',\n",
        "  ' But',\n",
        "  ' uh',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' that',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' we',\n",
        "  ' always',\n",
        "  ' uh',\n",
        "  ' I',\n",
        "  ' mean',\n",
        "  ' I',\n",
        "  \" 've\",\n",
        "  ' I',\n",
        "  \" 've\",\n",
        "  ' had',\n",
        "  ' a',\n",
        "  ' lot',\n",
        "  ' of',\n",
        "  ' good',\n",
        "  ' experiences',\n",
        "  ' with',\n",
        "  ' uh',\n",
        "  ' with',\n",
        "  ' many',\n",
        "  ' many',\n",
        "  ' people',\n",
        "  ' especially',\n",
        "  ' where',\n",
        "  ' they',\n",
        "  \" 've\",\n",
        "  ' had',\n",
        "  ' uh',\n",
        "  ' extended',\n",
        "  ' family',\n",
        "  '.'],\n",
        " 185: ['---A:  ',\n",
        "  ' And',\n",
        "  ' I',\n",
        "  ' and',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' kind',\n",
        "  ' of',\n",
        "  ' see',\n",
        "  ' that',\n",
        "  ' that',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' perhaps',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' we',\n",
        "  ' may',\n",
        "  ' need',\n",
        "  ' to',\n",
        "  ' like',\n",
        "  ' get',\n",
        "  ' close',\n",
        "  ' to',\n",
        "  ' the',\n",
        "  ' family',\n",
        "  ' environment',\n",
        "  ' and',\n",
        "  ' and',\n",
        "  ' get',\n",
        "  ' down',\n",
        "  ' to',\n",
        "  ' the',\n",
        "  ' values',\n",
        "  ' of',\n",
        "  ' you',\n",
        "  ' know'],\n",
        " 186: ['---B:  ', ' Uh-huh', '.'],\n",
        " 187: ['---A:  ', ' I', ' mean', ' uh', ' it', \" 's\"],\n",
        " 188: ['---A:  ',\n",
        "  ' money',\n",
        "  ' seems',\n",
        "  ' to',\n",
        "  ' be',\n",
        "  ' too',\n",
        "  ' big',\n",
        "  ' of',\n",
        "  ' an',\n",
        "  ' issue',\n",
        "  '.',\n",
        "  ' With',\n",
        "  ' with',\n",
        "  ' with',\n",
        "  ' with',\n",
        "  ' what',\n",
        "  \" 's\",\n",
        "  ' going',\n",
        "  ' on',\n",
        "  ' today'],\n",
        " 189: ['---B:  ', ' Oh', ' yeah', '.'],\n",
        " 190: ['---B:  ', ' sure', '.'],\n",
        " 191: ['---B:  ', ' realistically', ' it', ' is', '.'],\n",
        " 192: ['---A:  ',\n",
        "  ' and',\n",
        "  ' I',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' I',\n",
        "  ' think',\n",
        "  ' that',\n",
        "  ' we',\n",
        "  ' may',\n",
        "  ' not',\n",
        "  ' that',\n",
        "  ' may',\n",
        "  ' be',\n",
        "  ' you',\n",
        "  ' know',\n",
        "  ' perhaps',\n",
        "  ' if',\n",
        "  ' we',\n",
        "  ' put',\n",
        "  ' money',\n",
        "  ' on',\n",
        "  ' the',\n",
        "  ' back',\n",
        "  ' burner',\n",
        "  ' that',\n",
        "  ' may',\n",
        "  ' that',\n",
        "  ' may',\n",
        "  ' choose',\n",
        "  ' to',\n",
        "  ' alleviate',\n",
        "  ' a',\n",
        "  ' lot',\n",
        "  ' of',\n",
        "  ' the',\n",
        "  ' problem',\n",
        "  '.'],\n",
        " 193: ['---B:  ', ' Uh-huh', '.'],\n",
        " 194: ['---B:  ', ' That', ' would', ' certainly', ' help', '.'],\n",
        " 195: ['---A:  ',\n",
        "  ' I',\n",
        "  ' mean',\n",
        "  ' I',\n",
        "  ' mean',\n",
        "  ' we',\n",
        "  ' may',\n",
        "  ' not',\n",
        "  ' we',\n",
        "  ' may',\n",
        "  ' not',\n",
        "  ' have',\n",
        "  ' as',\n",
        "  ' high',\n",
        "  ' a',\n",
        "  ' standard',\n",
        "  ' of',\n",
        "  ' living'],\n",
        " 196: ['---B:  ', ' Uh-huh', '.'],\n",
        " 197: ['---A:  ',\n",
        "  ' but',\n",
        "  ' the',\n",
        "  ' qua-',\n",
        "  ' but',\n",
        "  ' actually',\n",
        "  ' have',\n",
        "  ' a',\n",
        "  ' truer',\n",
        "  ' standard',\n",
        "  ' of',\n",
        "  ' living',\n",
        "  '.'],\n",
        " 198: ['---B:  ', ' Right', '.'],\n",
        " 199: ['---B:  ',\n",
        "  ' That',\n",
        "  \" 's\",\n",
        "  ' just',\n",
        "  ' a',\n",
        "  ' matter',\n",
        "  ' of',\n",
        "  ' defining',\n",
        "  ' priorities',\n",
        "  ' I',\n",
        "  ' guess',\n",
        "  ' or',\n",
        "  ' some',\n",
        "  ' priorities',\n",
        "  ' anyway',\n",
        "  '.'],\n",
        " 200: ['---A:  ', ' Yeah', '.'],\n",
        " 201: ['---A:  ', ' Yeah', '.'],\n",
        " 202: ['---A:  ', ' Yeah', '.'],\n",
        " 203: ['---B:  ', ' I', ' think', ' you', \" 're\", ' right', '.'],\n",
        " 204: ['---A:  ', ' Okay', '.'],\n",
        " 205: ['---A:  ', ' Well', ' I', ' guess', ' that', ' was', ' it', '.'],\n",
        " 206: ['---B:  ', ' Okay', '.'],\n",
        " 207: ['---B:  ', ' It', ' was', ' good', ' talking', ' to', ' you', '.'],\n",
        " 208: ['---A:  ', ' Okay', '.'],\n",
        " 209: ['---B:  ', ' Yeah', '.'],\n",
        " 210: ['---A:  ', ' All', ' right', '.'],\n",
        " 211: ['---B:  ', ' Take', ' care', '.'],\n",
        " 212: ['---A:  ', ' Hey', '.'],\n",
        " 213: ['---B:  ', ' Bye-bye', '.'],\n",
        " 214: ['---A:  ', ' Bye-bye', '.']}"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trans['sw2005'][34]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "['---A:  ',\n",
        " ' and',\n",
        " ' um',\n",
        " ' she',\n",
        " ' had',\n",
        " ' used',\n",
        " ' the',\n",
        " ' walker',\n",
        " ' for',\n",
        " ' for',\n",
        " ' quite',\n",
        " ' some',\n",
        " ' time',\n",
        " ' probably',\n",
        " ' about',\n",
        " ' six',\n",
        " ' to',\n",
        " ' nine',\n",
        " ' months',\n",
        " '.']"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get a more user-friendly display by joining the separate words into one string per sentence."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\" \".join(trans['sw2005'][34])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "'---A:    and  um  she  had  used  the  walker  for  for  quite  some  time  probably  about  six  to  nine  months .'"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- total number of 'some' hits:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(somes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "2143"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Dataset clean-up"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Goal is to eliminate any unusable tokens, such as:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Alignment and transcript errors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that not all tokens are phone-transcribed as the <tt>s-ah-m</tt>."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "set([\"-\".join(s['phones']) for s in somes if s['phones']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "{'ay',\n",
        " 'ih-t-s',\n",
        " 's-ah',\n",
        " 's-ah-m',\n",
        " 's-ah-m-b-ah-d-iy',\n",
        " 's-ah-m-hh-aw',\n",
        " 's-ah-m-th-ih-ng',\n",
        " 's-ow-r-t',\n",
        " 't-ax',\n",
        " 'w-iy-l'}"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some of these are alignment and transcript errors, e.g. <tt>ay, ih-t-s, t-ax, w-iy-l</tt>. Some are mismatches between the original MS-State Switchboard and the re-worked NXT annotations, e.g. <tt>s-ah-m-b-ah-d-iy</tt> and neighbors. One is a disfluency: <tt>s-ah</tt>. I remove all of these: a total of 32 tokens."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "somes = [s for s in somes if s['phones'] == ['s','ah','m']]; len(somes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "2111"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some <i>some</i>s have no phone alignment available, but we seem to have gotten rid of them in the previous step (e.g. the tokens recognized by MS-Aligned Switchboard as <tt>something</tt>, but by NXT as <tt>some thing</tt>)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[s for s in somes if s['start'] == 'n/a' or s['end'] == 'n/a']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Working dataset for Ezra annotations"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "<i>some</i>s followed by hesitations or disfluencies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<i>some</i> may be followed by:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next_word = [hit['nextWord'] for hit in somes]\n",
      "fdist = nltk.FreqDist(next_word\n",
      "\"  \".join([s for s in fdist])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "'of  people  kind  some  uh  sort  things  other  more  good  NEW_SENT  reason  ways  money  time  cases  pretty  places  friends  real  way  I  place  really  day  you  problems  that  type  .  kids  little  new  nice  stuff  work  extent  point  sense  um  are  areas  bad  degree  experience  extra  interesting  serious  states  years  and  big  changes  companies  days  great  parts  programs  rain  schools  small  very  weird  advantages  but  chicken  children  color  countries  crazy  cross  different  every  form  from  guy  health  help  ice  idea  in  just  material  measure  odd  on  opinions  others  plants  problem  rather  recycling  responsibility  shows  such  there  tomatoes  training  types  young  EOF  a  about  activity  around  aspects  awful  back  black  book  broccoli  camping  channel  company  country  cousins  crab  cream  definitely  drug  fields  flooding  for  free  groups  guys  he  important  information  instances  interest  kid  lady  light  like  local  major  needlepoint  negatives  old  older  paint  particular  peace  personal  positive  pride  professions  quality  radishes  relatives  remodeling  respects  results  rewiring  rooms  savings  significant  simple  smaller  social  space  spare  special  strange  strong  tapes  teaching  the  times  traveling  trees  truth  volunteer  water  we  were  when  wonderful  wood  Academy  Cajun  Cokes  Danielle  European  Italian  Kurds  Lotus  Malaria  Miss  P  R  Saint  Spiro  T  Texas  V  ability  absolutely  accomplices  action  actress  adjustments  advertising  affection  afghans  allergies  also  amount  animals  apartments  apple  apples  applications  appointments  arts  as-  aspect  attention  aunts  available  away  baby-sitting  background  backup  baked  barbecueing  basic  beautiful  because  beet  beets  benches  bends  benefit  better  bibs  bicep  bins  bird  birds  bizarre  blackberries  blood  boating  bow  boy  brain  bread  brick  brutal  bucks  budgeting  buildings  butt  butter  by  cabinets  campaigns  candidates  cantaloupe  cars  cartoons  catamarans  certain  change  charcoal  cheap  cheddar  child  chocolate  chopped  church  civil  class  classes  classical  cloth  cloves  cocaine  cold  college  colleges  columns  comfort  compassion  compromise  connectors  consistency  consulting  contacts  continuity  conversation  cooking  cool  crafts  crawfish  credence  credit  crimes  cucumber  curbside  current  daffodils  damage  data  decent  dedication  definite  delicious  development  differences  dijon  dining  discipline  discrimination  districts  draft  drastic  dulcimer  during  e-  economic  education  educational  effect  elderly  enemies  energy  engineers  equipment  evenings  evidence  examples  expense  expertise  extended  fairly  families  family  famous  fanatic  fashions  fat  feel  feeling  fellowship  financial  fire  firewood  flickers  flounder  forms  freedoms  fruit  fundamental  funny  furniture  games  gardenias  gardening  garlic  gas  gauge  general  girl  go  government  gray  ground  group  guidelines  hail  ham  hard-boiled  here  high  highways  history  hoi  honor  horrible  houses  humanness  hummingbird  ideas  if  impact  improvement  improvements  incentive  incident  increases  independence  individual  industrial  industries  influence  inherent  innocent  innovative  insecticide  insight  interference  interviews  investigating  it  jobs  juries  jurisdictions  killer  kittens  knee  knowledge  lakes  laser  late  later  latitude  law  laws  lessons  level  liquid  list  litigation  lot  magazines  mailing  manner  marginally  marijuana  maybe  mayonnaise  medication  members  men  mental  military  minority  mock  modern  monster  movies  mums  murderers  muscle  musicals  my  names  negotiating  neighbors  nights  noise  nursing  occupations  ocean  oil  olives  one  onion  onions  ooze  opportunities  orange  order  organized  orientation  orthodontia  out  painting  pansies  paper  parent  parents  park  part  period  perspective  petting  pictures  piece  pineapple  pitching  planning  plum  political  poodles  posters  potato  potential  practice  pretrial  priorities  private  program  progressive  projects  promise  property  prunes  psychology  public  question  quick  quiet  quotas  race  radical  rafting  ratings  reading  red  reference  regards  relevance  relief  research  reservations  respect  reviews  rice  ridiculous  right  rocks  rolls  room  royalties  rule  rules  sailing  salesman  same  scallions  scandals  scholarships  school  science  seasoning  sections  sector  security  see  self  seminars  senator  senators  sensational  senses  sewing  shelves  shopping  short  show  sick  similar  size  skiing  smart  snickering  sociology  software  songs  sorts  specialty  stability  static  statistical  statistics  steps  sternness  sto-  stomping  stop  strawberries  strides  sub  subsidy  substance  substantial  success  sun  superficial  support  suspense  take  talk  taxable  technicality  television  termites  terrible  testing  their  they  thing  this  thoughts  tickets  to  tomato  too  tools  top  topics  tough  toys  track  traits  turn  two  typing  under  ungodly  unknown  unpopular  unusual  upbeat  useful  vacation  variety  visiting  visitor  walkie-talkies  wallpapering  warnings  wealth  wealthy  wear  well  what  wheel  while  who  wild  wine  wire  with  wo-  women  woodworking  yeah  yellow  yogurt  younger'"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some of these clearly include disfluencies, e.g. where the following word <tt>um,uh</tt>, a second <tt>some</tt>, punctuation, pronouns (most likely as part of an aside), incomplete words <tt>sto-, wo-</tt>. Let's not complicate the analysis. These tokens may have prosodic artifacts and may be difficult to annotate since they're not part of a \"complete thought\". But combing through all these following words may be hard. We could eliminate all unique bigrams, which makes the list of contexts we need to check more manageable, but then we would get rid of 465 tokens."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"  \".join([s for s in fdist if fdist[s] > 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "'of  people  kind  some  uh  sort  things  other  more  good  NEW_SENT  reason  ways  money  time  cases  pretty  places  friends  real  way  I  place  really  day  you  problems  that  type  .  kids  little  new  nice  stuff  work  extent  point  sense  um  are  areas  bad  degree  experience  extra  interesting  serious  states  years  and  big  changes  companies  days  great  parts  programs  rain  schools  small  very  weird  advantages  but  chicken  children  color  countries  crazy  cross  different  every  form  from  guy  health  help  ice  idea  in  just  material  measure  odd  on  opinions  others  plants  problem  rather  recycling  responsibility  shows  such  there  tomatoes  training  types  young  EOF  a  about  activity  around  aspects  awful  back  black  book  broccoli  camping  channel  company  country  cousins  crab  cream  definitely  drug  fields  flooding  for  free  groups  guys  he  important  information  instances  interest  kid  lady  light  like  local  major  needlepoint  negatives  old  older  paint  particular  peace  personal  positive  pride  professions  quality  radishes  relatives  remodeling  respects  results  rewiring  rooms  savings  significant  simple  smaller  social  space  spare  special  strange  strong  tapes  teaching  the  times  traveling  trees  truth  volunteer  water  we  were  when  wonderful  wood'"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len([s for s in fdist if fdist[s] == 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "465"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Can we eliminate bad contexts based on the POS of the following word? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next_POS = [hit['nextPOS'] for hit in somes]\n",
      "fdistPOS = nltk.FreqDist(next_POS)\n",
      "\"  \".join([s for s in fdistPOS])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "'NN  IN  NNS  JJ  RB  DT  UH  PRP  JJR  NEW_SENT  NNP  PUNC  WDT  VBP  CC  VBG  RBR  CD  EOF  EX  NNPS  PRP$  VBD  WP  WRB  FW  GW  JJ|RB  SYM  TO  VB  VBN  XX  ^NNS'"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some of these are reasonable: NN, NNS (sg nouns), JJ (Adjective). Some don't seem so reasonable, like PUNC (punctuation). Let's look at IN (preposition), where we might except partitive \"of\", but not many more."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "set([hit['nextWord'] for hit in somes if hit['nextPOS'] == 'IN'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "{'about',\n",
        " 'around',\n",
        " 'because',\n",
        " 'by',\n",
        " 'during',\n",
        " 'for',\n",
        " 'from',\n",
        " 'if',\n",
        " 'in',\n",
        " 'like',\n",
        " 'of',\n",
        " 'on',\n",
        " 'under',\n",
        " 'with'}"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[hit for hit in somes if hit['nextPOS'] == 'IN' and hit['nextWord'] in ['about','around','by','for','in','on','under','with']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "[{'accent': 'NoAnnotation',\n",
        "  'end': '227.502125',\n",
        "  'ezraID': 99,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's106_20',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'in',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '227.175500',\n",
        "  'swbfile': 'sw2095.A',\n",
        "  'terminalID': 's106_16'},\n",
        " {'accent': 'NoAnnotation',\n",
        "  'end': '422.599000',\n",
        "  'ezraID': 146,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's133_97',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'with',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '422.309000',\n",
        "  'swbfile': 'sw2130.A',\n",
        "  'terminalID': 's133_96'},\n",
        " {'accent': 'NoAnnotation',\n",
        "  'end': '365.948875',\n",
        "  'ezraID': 220,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's234_6',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'under',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '365.708875',\n",
        "  'swbfile': 'sw2226.B',\n",
        "  'terminalID': 's234_5'},\n",
        " {'accent': 'NoAnnotation',\n",
        "  'end': '153.142875',\n",
        "  'ezraID': 293,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's70_11',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'around',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '152.912875',\n",
        "  'swbfile': 'sw2299.B',\n",
        "  'terminalID': 's70_10'},\n",
        " {'accent': 'NoAnnotation',\n",
        "  'end': '309.415625',\n",
        "  'ezraID': 543,\n",
        "  'focus': ('background', 'word'),\n",
        "  'nextID': 's208_31',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'by',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '309.175625',\n",
        "  'swbfile': 'sw2479.A',\n",
        "  'terminalID': 's208_30'},\n",
        " {'accent': 'NoAnnotation',\n",
        "  'end': '319.066125',\n",
        "  'ezraID': 988,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's155_11',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'on',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '318.756125',\n",
        "  'swbfile': 'sw2876.A',\n",
        "  'terminalID': 's155_10'},\n",
        " {'accent': ('full', 'plain'),\n",
        "  'end': '314.748250',\n",
        "  'ezraID': 1042,\n",
        "  'focus': ('subset', 'word'),\n",
        "  'nextID': 's148_41',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'on',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '314.508250',\n",
        "  'swbfile': 'sw2969.A',\n",
        "  'terminalID': 's148_40'},\n",
        " {'accent': 'NoAnnotation',\n",
        "  'end': '353.077125',\n",
        "  'ezraID': 1150,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's78_9',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'around',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '352.797125',\n",
        "  'swbfile': 'sw3083.A',\n",
        "  'terminalID': 's78_8'},\n",
        " {'accent': 'NoAnnotation',\n",
        "  'end': '258.076250',\n",
        "  'ezraID': 1535,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's92_9',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'on',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '257.356250',\n",
        "  'swbfile': 'sw3514.B',\n",
        "  'terminalID': 's92_8'},\n",
        " {'accent': 'NoAnnotation',\n",
        "  'end': '194.278500',\n",
        "  'ezraID': 1568,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's57_15',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'in',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '193.996375',\n",
        "  'swbfile': 'sw3574.A',\n",
        "  'terminalID': 's57_13'},\n",
        " {'accent': 'NoAnnotation',\n",
        "  'end': '110.153875',\n",
        "  'ezraID': 1582,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's45_17',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'for',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '109.825875',\n",
        "  'swbfile': 'sw3576.B',\n",
        "  'terminalID': 's45_15'},\n",
        " {'accent': 'NoAnnotation',\n",
        "  'end': '243.870250',\n",
        "  'ezraID': 1701,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's77_10',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'about',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '243.660250',\n",
        "  'swbfile': 'sw3825.B',\n",
        "  'terminalID': 's77_7'},\n",
        " {'accent': 'NoAnnotation',\n",
        "  'end': '3.793000',\n",
        "  'ezraID': 1971,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's2_5',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'about',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '3.593000',\n",
        "  'swbfile': 'sw4356.B',\n",
        "  'terminalID': 's2_4'},\n",
        " {'accent': 'NoAnnotation',\n",
        "  'end': '217.721500',\n",
        "  'ezraID': 2025,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's54_11',\n",
        "  'nextPOS': 'IN',\n",
        "  'nextWord': 'for',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '217.461500',\n",
        "  'swbfile': 'sw4603.B',\n",
        "  'terminalID': 's54_8'}]"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some of these are more disfluencies."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\" \".join(trans['sw2095'][106])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "'---A:    I  I  think  in  in  some  in  some  respects  it  probably  MUMBLEx  more  tolerable .'"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I could go look at the disfluency annotation, but that won't be enough either. There are cases where <i>some</i> ends a sentence and the sentence is repaired soon after, but the annotation does not mark it as a disfluency. So really, I should go over every individual example and make sure it's not disfluent."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some <i>some</i>s enter gapping constructions (no head noun), which I think I should keep."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\" \".join(trans['sw2130'][133])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "\"---A:    and  I  think  that  's  the  problem  the  P  L  O  has  is  that  when  they  whenever  one  group  of  them  decides  that  they  're  going  to  negotiate  or  they  're  going  to  do  something  they  're  going  to  try  to  make  some  peace  but  uh  the  end  result  is  that  they  there  so  many  factions  of  them  and  uh  some  more  violent  than  others  some  with  a  certain  agenda  different  than  the  others  or  they  split\""
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Take only non-unique bigrams"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nonunique = [s for s in fdist if fdist[s] > 1]; print nonunique"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['of', 'people', 'kind', 'some', 'uh', 'sort', 'things', 'other', 'more', 'good', 'NEW_SENT', 'reason', 'ways', 'money', 'time', 'cases', 'pretty', 'places', 'friends', 'real', 'way', 'I', 'place', 'really', 'day', 'you', 'problems', 'that', 'type', '.', 'kids', 'little', 'new', 'nice', 'stuff', 'work', 'extent', 'point', 'sense', 'um', 'are', 'areas', 'bad', 'degree', 'experience', 'extra', 'interesting', 'serious', 'states', 'years', 'and', 'big', 'changes', 'companies', 'days', 'great', 'parts', 'programs', 'rain', 'schools', 'small', 'very', 'weird', 'advantages', 'but', 'chicken', 'children', 'color', 'countries', 'crazy', 'cross', 'different', 'every', 'form', 'from', 'guy', 'health', 'help', 'ice', 'idea', 'in', 'just', 'material', 'measure', 'odd', 'on', 'opinions', 'others', 'plants', 'problem', 'rather', 'recycling', 'responsibility', 'shows', 'such', 'there', 'tomatoes', 'training', 'types', 'young', 'EOF', 'a', 'about', 'activity', 'around', 'aspects', 'awful', 'back', 'black', 'book', 'broccoli', 'camping', 'channel', 'company', 'country', 'cousins', 'crab', 'cream', 'definitely', 'drug', 'fields', 'flooding', 'for', 'free', 'groups', 'guys', 'he', 'important', 'information', 'instances', 'interest', 'kid', 'lady', 'light', 'like', 'local', 'major', 'needlepoint', 'negatives', 'old', 'older', 'paint', 'particular', 'peace', 'personal', 'positive', 'pride', 'professions', 'quality', 'radishes', 'relatives', 'remodeling', 'respects', 'results', 'rewiring', 'rooms', 'savings', 'significant', 'simple', 'smaller', 'social', 'space', 'spare', 'special', 'strange', 'strong', 'tapes', 'teaching', 'the', 'times', 'traveling', 'trees', 'truth', 'volunteer', 'water', 'we', 'were', 'when', 'wonderful', 'wood']\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Tests for exclusion"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[hit for hit in somes if hit['nextWord'] == 'the']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "[{'accent': 'NoAnnotation',\n",
        "  'end': '211.359500',\n",
        "  'ezraID': 165,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's58_6',\n",
        "  'nextPOS': 'DT',\n",
        "  'nextWord': 'the',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '211.079500',\n",
        "  'swbfile': 'sw2139.B',\n",
        "  'terminalID': 's58_3'},\n",
        " {'accent': 'NoAnnotation',\n",
        "  'end': '481.094500',\n",
        "  'ezraID': 534,\n",
        "  'focus': 'NoAnnotation',\n",
        "  'nextID': 's256_5',\n",
        "  'nextPOS': 'DT',\n",
        "  'nextWord': 'the',\n",
        "  'phones': ['s', 'ah', 'm'],\n",
        "  'start': '480.917375',\n",
        "  'swbfile': 'sw2472.A',\n",
        "  'terminalID': 's256_4'}]"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\" \".join(trans['sw2472'][256])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "'---A:    I  stir  fried  some  the  other  night  though .'"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- 'some','uh','um' for hesitations, disfluencies, errors etc.\n",
      "- 'EOF' for lack of following context, which makes it dissimilar to other tokens"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exclude = ['some','uh','um','EOF']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keep = [w for w in nonunique if w not in exclude]\n",
      "somes2 = [s for s in somes if s['nextWord'] in keep]\n",
      "len(somes2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "1543"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Still too many for a pilot. Maybe sample out of these so that I have a similar distribution of following parts of speech?]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "See if any don't have enough preceding/following context."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len([s for s in somes if 'LC' not in s or 'RC' not in s])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "243"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Ezra dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('swbsomesEZRA.pkl','r')\n",
      "somesE = pickle.load(f)\n",
      "len(somesE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "1366"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "somesE[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "{'LC': \"[...]\\n---A:  [...]  of  the  first  type  of  privacy  seemed  invaded  to  me  and  very  much  everyday  in  this  country but  in  the  second  time  at  least  overtly  uh  where  someone  comes  in  and  uh  finds  out  information  about  you  that  should  be  private  uh  does  not  seem  uh  um  obviously  everyday .\\n---B:    I  I  think  I  agree  with  that . I  think  in  a  good  example  on  the  typical  thing  that  happens  uh  when  the  phone  rang  and  it  's  T  I  calling  my  immediate  reaction  is  that  it  's  some  sort  of  strange  phone  message >>>\",\n",
        " 'LC_startID': 's4_7',\n",
        " 'LC_startTime': '32.454625',\n",
        " 'RC': \" <<<  and  then  I  realize  oh  no  this  is  something  I  solicited\\n---A:    That  's  right .\\n---B:    so  my  immediate  reaction  was  one  of  that  sense  of  invasion but  after  that  I  realized  no  I  I  really  wanted  this and  it  was  sort  of  exciting and  so  that  was  almost  an  example  of  s-  an  invasion  that  turns  out [...]\",\n",
        " 'RC_endID': 's13_15',\n",
        " 'RC_endTime': '77.130000',\n",
        " 'accent': 'NoAnnotation',\n",
        " 'end': '62.534750',\n",
        " 'ezraID': 4,\n",
        " 'focus': 'unfocused',\n",
        " 'nextID': 's7_42',\n",
        " 'nextPOS': 'NN',\n",
        " 'nextWord': 'sort',\n",
        " 'phones': ['s', 'ah', 'm'],\n",
        " 'start': '62.384750',\n",
        " 'swbfile': 'sw2012.B',\n",
        " 'terminalID': 's7_41'}"
       ]
      }
     ],
     "prompt_number": 36
    }
   ],
   "metadata": {}
  }
 ]
}